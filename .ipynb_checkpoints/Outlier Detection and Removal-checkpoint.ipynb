{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5462f57d-5a27-4c55-90dc-75c8a37a2be3",
   "metadata": {},
   "source": [
    "## Outlier identification and Removal\n",
    "Outliers are observations unlike other observations. They can be identified by statistical methods. \n",
    "But before we look for an outlier, lets define a dataset we can use to test the methods.\n",
    "\n",
    "We will generate a population of 10,000 random numbers drawn for a Gaussian distribution with a mean of 50 and a standard deviation of 5. \n",
    "The numbers drawn from a Gausian distribution will have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8318b01-cca2-45ef-8b55-9fc6950e06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is 50.049 and the standard deviation is 4.994\n"
     ]
    }
   ],
   "source": [
    "# We will use the numpy library.\n",
    "import numpy as np\n",
    "# We will generate random data of 1 seed\n",
    "np.random.seed(1)\n",
    "data = 5* np.random.randn(10000) + 50\n",
    "Mean =np.mean(data)\n",
    "Standard_deviation = np.std(data)\n",
    "print(f\"The mean is {Mean:.3f} and the standard deviation is {Standard_deviation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67385dd-1942-4871-96a2-6abc7e8ea90f",
   "metadata": {},
   "source": [
    "### Standard Deviation Method.\n",
    "given mu and sigma, a simple way to identifu outliers is to compute a z-score for every xi, which is defined as the number of standard deviations away xi is from mean data values that have z-score sigma greater than a threshold, for example, of three, are declared to be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3db13b4-61ec-4f50-be76-79e13a447a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers 29\n",
      "Non-Outlier observations 9971\n"
     ]
    }
   ],
   "source": [
    "cut_off = Standard_deviation * 3\n",
    "lower = Mean - cut_off\n",
    "upper = Mean + cut_off\n",
    "outliers = [x for x in data if x< lower or x> upper]\n",
    "length_of_outliers = len(outliers)\n",
    "print(f\"Identified outliers {length_of_outliers}\")\n",
    "non_outliers = [x for x in data if x>= lower and x<= upper]\n",
    "length_of_non_outliers = len(non_outliers)\n",
    "print(f\"Non-Outlier observations {length_of_non_outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df13c5-1d0c-4f7d-adfd-8c6148f53398",
   "metadata": {},
   "source": [
    "# Inter Quartile Range Method\n",
    "Not all data is normal enough to be treated by the Gaussian distribution. A good statistic for summarizing a non-Gaussian distribution smaple of data is the Interquartile Range, or IQR for short.\n",
    "It is calculate as the 25th and 75th percentiles of the data and defines the box in a box and whisker plot.\n",
    "The 50th percentile is the middle value, or the average of the two middle values for an even number of examples. If we had 10,000 samples, then the 50th percentile would be the average of the 5000th and 5001st values.\n",
    "Statistics-based outlier detection techniques assume that the normal data points would appear in high probability regions of a stochastic model, while outliers would occur in the low probability regions of a stochastic model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51dcf90a-fe0b-461a-844c-ad82ec30e4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentiles of Q25 is 46.685 and Q75 is 53.359. The Interquartile range is 6.674 \n",
      "Identified outliers 81\n",
      "Non Outliers are 9919\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "data = 5 * np.random.randn(10000) + 50\n",
    "#Now we will calculate the interquartile range\n",
    "q25 = np.percentile(data, 25)\n",
    "q75 = np.percentile(data, 75)\n",
    "iqr = q75 - q25 \n",
    "print(f\"percentiles of Q25 is {q25:.3f} and Q75 is {q75:.3f}. The Interquartile range is {iqr:.3f} \")\n",
    "cut_off = iqr * 1.5\n",
    "lower = q25 - cut_off\n",
    "upper = q75 + cut_off\n",
    "outliers = [x for x in data if x < lower or x> upper]\n",
    "No_outliers = len(outliers)\n",
    "print(f\"Identified outliers {No_outliers}\")\n",
    "Non_outliers = [x for x in data if x >= lower and x <= upper]\n",
    "length_non_outliers = len(Non_outliers)\n",
    "print(f\"Non Outliers are {length_non_outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c103a16-6700-4b63-bf19-1cd8bf7a5ded",
   "metadata": {},
   "source": [
    "## Automatic Outlier Detection \n",
    "Another approach to tackle this problem in outlier detection is one-class calssification.\n",
    "\n",
    "For this we will use Boston housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7391f91c-f6c4-4cb9-b495-0f062580c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outlier removal: (339, 13) (339,)\n",
      "After outlier removal: (305, 13) (305,)\n",
      "The mean absolute error is 3.36\n"
     ]
    }
   ],
   "source": [
    "# First we will import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "housing_df = pd.read_csv(url, header=None)\n",
    "\n",
    "# Convert the dataframe into a numpy array\n",
    "data = housing_df.values\n",
    "\n",
    "# Split into features and target\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(\"Before outlier removal:\", X_train.shape, y_train.shape)\n",
    "\n",
    "# Apply Local Outlier Factor\n",
    "lof = LocalOutlierFactor()\n",
    "lof_X = lof.fit_predict(X_train)\n",
    "\n",
    "# Create a mask for non-outliers\n",
    "mask = lof_X != -1\n",
    "X_train_clean = X_train[mask, :]\n",
    "y_train_clean = y_train[mask]\n",
    "print(\"After outlier removal:\", X_train_clean.shape, y_train_clean.shape)\n",
    "\n",
    "# Train Linear Regression model on clean data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate using Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"The mean absolute error is {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80208d8-c202-45c6-816d-b6ba7f5a0ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
